(window.webpackJsonp=window.webpackJsonp||[]).push([[178],{550:function(a,s,t){"use strict";t.r(s);var r=t(8),e=Object(r.a)({},(function(){var a=this,s=a._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"spark安装"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#spark安装"}},[a._v("#")]),a._v(" spark安装")]),a._v(" "),s("h2",{attrs:{id:"本内容你将获得"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#本内容你将获得"}},[a._v("#")]),a._v(" 本内容你将获得")]),a._v(" "),s("ul",[s("li",[a._v("centos7 上安装 spark")]),a._v(" "),s("li",[a._v("验证spark安装")])]),a._v(" "),s("h2",{attrs:{id:"软件安装"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#软件安装"}},[a._v("#")]),a._v(" 软件安装")]),a._v(" "),s("h4",{attrs:{id:"说明"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#说明"}},[a._v("#")]),a._v(" 说明")]),a._v(" "),s("ul",[s("li",[a._v("spark依赖 java环境")]),a._v(" "),s("li",[a._v("hive on spark引擎依赖hadoop环境")])]),a._v(" "),s("h3",{attrs:{id:"安装开始"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#安装开始"}},[a._v("#")]),a._v(" 安装开始")]),a._v(" "),s("h5",{attrs:{id:"上传spark-2-4-8-bin-without-hadoop-scala-2-12-tgz到服务器-root-tools目录"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#上传spark-2-4-8-bin-without-hadoop-scala-2-12-tgz到服务器-root-tools目录"}},[a._v("#")]),a._v(" 上传spark-2.4.8-bin-without-hadoop-scala-2.12.tgz到服务器/root/tools目录")]),a._v(" "),s("p",[a._v("解压spark安装包")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /root/tools\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("tar")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-xvzf")]),a._v(" spark-2.4.8-bin-without-hadoop-scala-2.12.tgz\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("mv")]),a._v(" spark-2.4.8-bin-without-hadoop-scala-2.12 spark-2.4.8-pure    \n")])])]),s("h5",{attrs:{id:"配置spark-defaults-conf-在文件最后增加配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#配置spark-defaults-conf-在文件最后增加配置"}},[a._v("#")]),a._v(" 配置spark-defaults.conf，在文件最后增加配置")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("hadoop fs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-mkdir")]),a._v(" /spark-logs            "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#在hdfs中创建/spark-logs目录")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /root/tools/spark-2.4.8-pure/conf\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("vi")]),a._v(" spark-defaults.conf\n\n spark.eventLog.enabled           "),s("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n spark.eventLog.dir               hdfs://hadoopmaster:9000/spark-logs\n spark.history.fs.logDirectory    hdfs://hadoopmaster:9000/spark-logs\n spark.serializer                 org.apache.spark.serializer.KryoSerializer\n spark.driver.memory              5g\n spark.executor.extraJavaOptions  "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-XX:+PrintGCDetails")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-Dkey")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("value "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-Dnumbers")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"one two three"')]),a._v("\n spark.history.ui.port            "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("18080")]),a._v("\n spark.history.fs.update.interval 10s\n")])])]),s("h5",{attrs:{id:"配置spark-env-sh-在文件最后增加配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#配置spark-env-sh-在文件最后增加配置"}},[a._v("#")]),a._v(" 配置spark-env.sh，在文件最后增加配置")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /root/tools/spark-2.4.8-pure/conf\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("vi")]),a._v(" spark-env.sh\n\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SPARK_HOME")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/root/tools/spark-2.4.8-pure\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SCALA_HOME")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/root/tools/scala-2.12.15\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("JAVA_HOME")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/root/tools/jdk1.8.0_333\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")])]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$PATH")]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$JAVA_HOME")]),a._v("/bin:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/bin:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/sbin:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$SCALA_HOME")]),a._v("/bin\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_CONF_DIR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/etc/hadoop\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("YARN_CONF_DIR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/etc/hadoop\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SPARK_LOCAL_DIRS")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/root/tools/spark-2.4.8-pure\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SPARK_LIBARY_PATH")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(".:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$JAVA_HOME")]),a._v("/lib:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$JAVA_HOME")]),a._v("/jre/lib:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/lib/native\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#export SPAR_MASTER_PORT=7077")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SPARK_MASTER_HOST")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("hadoopmaster\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SPARK_HISTORY_OPTS")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=3 -Dspark.history.fs.logDirectory=hdfs://hadoopmaster:9000/spark-logs"')]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# HADOOP_HOME 会从hive-env.sh 带过来，这里仅为Spark 单独运行服务")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_HOME")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/root/tools/hadoop-3.3.4\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 无论Spark 纯净版还是Hive on Spark 没有SPARK_DIST_CLASSPATH 都不能运行")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SPARK_DIST_CLASSPATH")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$(")]),a._v("$"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("HADOOP_HOME"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("/bin/hdfs classpath"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v(")")])]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# YARN_CONF_DIR 仅用于Spark 和YARN 对接，跟Hive on Spark 无关")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("YARN_CONF_DIR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("${HADOOP_HOME}")]),a._v("/etc/hadoop\n"),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"spark-env.sh"')]),a._v(" 87L, 5297C written\n")])])]),s("h5",{attrs:{id:"配置spark环境变量"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#配置spark环境变量"}},[a._v("#")]),a._v(" 配置spark环境变量")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[a._v("vi")]),a._v(" /etc/profile\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#spark")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("SPARK_HOME")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/root/tools/spark-2.4.8-pure\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_CONF_DIR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/etc/hadoop\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("LD_LIBRARY_PATH")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/lib/native:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$LD_LIBRARY_PATH")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")])]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$SPARK_HOME")]),a._v("/bin:"),s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$PATH")]),a._v("\n")])])]),s("p",[a._v("保存后，source /etc/profile  使环境配置生效")]),a._v(" "),s("h5",{attrs:{id:"上传jars到hdfs目录"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#上传jars到hdfs目录"}},[a._v("#")]),a._v(" 上传jars到hdfs目录")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /root/tools/spark-2.4.8-pure/jars\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("mv")]),a._v(" orc-core-1.5.5-nohive.jar orc-core-1.5.5-nohive.jar.bak\nhadoop fs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-mkdir")]),a._v(" /spark2-jars\nhadoop dfs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-put")]),a._v(" *.jar /spark2-jars\n")])])]),s("h5",{attrs:{id:"测试-spark"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#测试-spark"}},[a._v("#")]),a._v(" 测试 spark")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /root/tools/spark-2.4.8-pure/bin\n./run-example SparkPi "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("\n")])])]),s("p",[a._v("在打印的日志中找到结果值: Pi is roughly 3.1434191434191433,证明spark部署成功")]),a._v(" "),s("h5",{attrs:{id:"启停"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#启停"}},[a._v("#")]),a._v(" 启停")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /root/tools/spark-2.4.8-pure/sbin\n./start-all.sh            --启动\n./stop-all.sh             --停止\n./start-history-server.sh --启动历史服务\n./stop-history-server.sh  --停止历史服务\n")])])]),s("h2",{attrs:{id:"其他"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#其他"}},[a._v("#")]),a._v(" 其他")]),a._v(" "),s("ul",[s("li",[a._v("无")])])])}),[],!1,null,null,null);s.default=e.exports}}]);